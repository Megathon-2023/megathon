{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aG2gSNd1himf",
        "outputId": "7ddf4fda-a64f-45e3-ee6f-a60690f0e4b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optimum[exporters-tf]\n",
            "  Downloading optimum-1.13.2.tar.gz (300 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/301.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/301.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.0/301.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting coloredlogs (from optimum[exporters-tf])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum[exporters-tf]) (1.12)\n",
            "Collecting transformers[sentencepiece]>=4.26.0 (from optimum[exporters-tf])\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from optimum[exporters-tf]) (2.1.0+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from optimum[exporters-tf]) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optimum[exporters-tf]) (1.23.5)\n",
            "Collecting huggingface-hub>=0.8.0 (from optimum[exporters-tf])\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from optimum[exporters-tf])\n",
            "  Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow<=2.12.1,>=2.4 (from optimum[exporters-tf])\n",
            "  Downloading tensorflow-2.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tf2onnx (from optimum[exporters-tf])\n",
            "  Downloading tf2onnx-1.15.1-py3-none-any.whl (454 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.7/454.7 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx (from optimum[exporters-tf])\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime (from optimum[exporters-tf])\n",
            "  Downloading onnxruntime-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm (from optimum[exporters-tf])\n",
            "  Downloading timm-0.9.8-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from optimum[exporters-tf]) (3.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum[exporters-tf]) (3.12.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum[exporters-tf]) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum[exporters-tf]) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum[exporters-tf]) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum[exporters-tf]) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum[exporters-tf]) (4.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (23.5.26)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow<=2.12.1,>=2.4->optimum[exporters-tf])\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (1.59.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (0.4.16)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow<=2.12.1,>=2.4->optimum[exporters-tf])\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (1.16.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow<=2.12.1,>=2.4->optimum[exporters-tf])\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow<=2.12.1,>=2.4->optimum[exporters-tf])\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (2.3.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (0.34.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[exporters-tf]) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[exporters-tf]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[exporters-tf]) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.26.0->optimum[exporters-tf]) (2023.6.3)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers[sentencepiece]>=4.26.0->optimum[exporters-tf])\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers[sentencepiece]>=4.26.0->optimum[exporters-tf])\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]>=4.26.0->optimum[exporters-tf])\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting humanfriendly>=9.1 (from coloredlogs->optimum[exporters-tf])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[exporters-tf]) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets->optimum[exporters-tf])\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[exporters-tf]) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[exporters-tf]) (3.4.1)\n",
            "Collecting multiprocess (from datasets->optimum[exporters-tf])\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[exporters-tf]) (3.8.6)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum[exporters-tf]) (1.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm->optimum[exporters-tf]) (0.16.0+cu118)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (0.41.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[exporters-tf]) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[exporters-tf]) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[exporters-tf]) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[exporters-tf]) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[exporters-tf]) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[exporters-tf]) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[exporters-tf]) (1.3.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (1.11.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum[exporters-tf]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum[exporters-tf]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum[exporters-tf]) (2023.7.22)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (3.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (3.0.1)\n",
            "Collecting huggingface-hub>=0.8.0 (from optimum[exporters-tf])\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->optimum[exporters-tf]) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum[exporters-tf]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum[exporters-tf]) (2023.3.post1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm->optimum[exporters-tf]) (9.4.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<=2.12.1,>=2.4->optimum[exporters-tf]) (3.2.2)\n",
            "Building wheels for collected packages: optimum\n",
            "  Building wheel for optimum (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optimum: filename=optimum-1.13.2-py3-none-any.whl size=395599 sha256=3343b9881a80a59a3c50ea21c231ebad9ba16c7859665fb136623cf58ae987b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/b7/2c/79405d98f0943373d8546daeae25a3d377f7659ca0cbe48699\n",
            "Successfully built optimum\n",
            "Installing collected packages: sentencepiece, tensorflow-estimator, safetensors, onnx, keras, humanfriendly, gast, dill, tf2onnx, multiprocess, huggingface-hub, coloredlogs, tokenizers, onnxruntime, transformers, timm, tensorboard, datasets, tensorflow, optimum\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.14.0\n",
            "    Uninstalling tensorflow-estimator-2.14.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.14.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.14.0\n",
            "    Uninstalling keras-2.14.0:\n",
            "      Successfully uninstalled keras-2.14.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.4\n",
            "    Uninstalling gast-0.5.4:\n",
            "      Successfully uninstalled gast-0.5.4\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.14.1\n",
            "    Uninstalling tensorboard-2.14.1:\n",
            "      Successfully uninstalled tensorboard-2.14.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.14.0\n",
            "    Uninstalling tensorflow-2.14.0:\n",
            "      Successfully uninstalled tensorflow-2.14.0\n",
            "Successfully installed coloredlogs-15.0.1 datasets-2.14.6 dill-0.3.7 gast-0.4.0 huggingface-hub-0.17.3 humanfriendly-10.0 keras-2.12.0 multiprocess-0.70.15 onnx-1.15.0 onnxruntime-1.16.1 optimum-1.13.2 safetensors-0.4.0 sentencepiece-0.1.99 tensorboard-2.12.3 tensorflow-2.12.1 tensorflow-estimator-2.12.0 tf2onnx-1.15.1 timm-0.9.8 tokenizers-0.14.1 transformers-4.34.1\n"
          ]
        }
      ],
      "source": [
        "!pip install optimum[exporters-tf]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!optimum-cli export tflite --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umtsAYFZh_2p",
        "outputId": "d4a62f29-ff4e-45b1-bb4f-282907b0c911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-28 18:25:08.952193: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "usage: optimum-cli export tflite [-h] -m MODEL [--task TASK] [--atol ATOL]\n",
            "                                 [--pad_token_id PAD_TOKEN_ID] [--cache_dir CACHE_DIR]\n",
            "                                 [--trust-remote-code] [--batch_size BATCH_SIZE]\n",
            "                                 [--sequence_length SEQUENCE_LENGTH] [--num_choices NUM_CHOICES]\n",
            "                                 [--width WIDTH] [--height HEIGHT] [--num_channels NUM_CHANNELS]\n",
            "                                 [--feature_size FEATURE_SIZE] [--nb_max_frames NB_MAX_FRAMES]\n",
            "                                 [--audio_sequence_length AUDIO_SEQUENCE_LENGTH]\n",
            "                                 [--quantize {int8-dynamic,int8,int8x16,fp16}]\n",
            "                                 [--fallback_to_float] [--inputs_type {int8,uint8}]\n",
            "                                 [--outputs_type {int8,uint8}]\n",
            "                                 [--calibration_dataset CALIBRATION_DATASET]\n",
            "                                 [--calibration_dataset_config_name CALIBRATION_DATASET_CONFIG_NAME]\n",
            "                                 [--num_calibration_samples NUM_CALIBRATION_SAMPLES]\n",
            "                                 [--calibration_split CALIBRATION_SPLIT]\n",
            "                                 [--primary_key PRIMARY_KEY] [--secondary_key SECONDARY_KEY]\n",
            "                                 [--question_key QUESTION_KEY] [--context_key CONTEXT_KEY]\n",
            "                                 [--image_key IMAGE_KEY]\n",
            "                                 output\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "\n",
            "Required arguments:\n",
            "  -m MODEL, --model MODEL\n",
            "                        Model ID on huggingface.co or path on disk to load model from.\n",
            "  output                Path indicating the directory where to store generated TFLite model.\n",
            "\n",
            "Optional arguments:\n",
            "  --task TASK           The task to export the model for. If not specified, the task will be auto-\n",
            "                        inferred based on the model. Available tasks depend on the model, but are\n",
            "                        among: ['text-classification', 'zero-shot-image-classification', 'zero-\n",
            "                        shot-object-detection', 'image-to-text', 'stable-diffusion', 'question-\n",
            "                        answering', 'image-classification', 'object-detection', 'audio-\n",
            "                        classification', 'fill-mask', 'mask-generation', 'automatic-speech-\n",
            "                        recognition', 'feature-extraction', 'semantic-segmentation', 'multiple-\n",
            "                        choice', 'audio-frame-classification', 'masked-im', 'audio-xvector',\n",
            "                        'conversational', 'text2text-generation', 'image-segmentation', 'stable-\n",
            "                        diffusion-xl', 'token-classification', 'text-generation']. For decoder\n",
            "                        models, use `xxx-with-past` to export the model using past key values in\n",
            "                        the decoder.\n",
            "  --atol ATOL           If specified, the absolute difference tolerance when validating the model.\n",
            "                        Otherwise, the default atol for the model will be used.\n",
            "  --pad_token_id PAD_TOKEN_ID\n",
            "                        This is needed by some models, for some tasks. If not provided, will\n",
            "                        attempt to use the tokenizer to guess it.\n",
            "  --cache_dir CACHE_DIR\n",
            "                        Path indicating where to store cache.\n",
            "  --trust-remote-code   Allow to use custom code for the modeling hosted in the model repository.\n",
            "                        This option should only be set for repositories you trust and in which you\n",
            "                        have read the code, as it will execute on your local machine arbitrary\n",
            "                        code present in the model repository.\n",
            "\n",
            "Input shapes:\n",
            "  --batch_size BATCH_SIZE\n",
            "                        Batch size that the TFLite exported model will be able to take as input.\n",
            "  --sequence_length SEQUENCE_LENGTH\n",
            "                        Sequence length that the TFLite exported model will be able to take as\n",
            "                        input.\n",
            "  --num_choices NUM_CHOICES\n",
            "                        Only for the multiple-choice task. Num choices that the TFLite exported\n",
            "                        model will be able to take as input.\n",
            "  --width WIDTH         Vision tasks only. Image width that the TFLite exported model will be able\n",
            "                        to take as input.\n",
            "  --height HEIGHT       Vision tasks only. Image height that the TFLite exported model will be\n",
            "                        able to take as input.\n",
            "  --num_channels NUM_CHANNELS\n",
            "                        Vision tasks only. Number of channels used to represent the image that the\n",
            "                        TFLite exported model will be able to take as input. (GREY = 1, RGB = 3,\n",
            "                        ARGB = 4)\n",
            "  --feature_size FEATURE_SIZE\n",
            "                        Audio tasks only. Feature dimension of the extracted features by the\n",
            "                        feature extractor that the TFLite exported model will be able to take as\n",
            "                        input.\n",
            "  --nb_max_frames NB_MAX_FRAMES\n",
            "                        Audio tasks only. Maximum number of frames that the TFLite exported model\n",
            "                        will be able to take as input.\n",
            "  --audio_sequence_length AUDIO_SEQUENCE_LENGTH\n",
            "                        Audio tasks only. Audio sequence length that the TFLite exported model\n",
            "                        will be able to take as input.\n",
            "\n",
            "Quantization:\n",
            "  --quantize {int8-dynamic,int8,int8x16,fp16}\n",
            "                        The method of quantization to perform, possible choices: \"int8-dynamic\",\n",
            "                        \"int8\", \"int8x16\", \"fp16\". No quantization will happen if left\n",
            "                        unspecified.\n",
            "  --fallback_to_float   Whether to fall back to the float implementation for operators without an\n",
            "                        integer implementation. This needs to be disabled for integer-only\n",
            "                        hardware.\n",
            "  --inputs_type {int8,uint8}\n",
            "                        The inputs will be expected to be of the specified type. This is useful\n",
            "                        for integer-only hardware.\n",
            "  --outputs_type {int8,uint8}\n",
            "                        The outputs will be of the specified type. This is useful for integer-only\n",
            "                        hardware.\n",
            "\n",
            "Quantization Calibration dataset:\n",
            "  --calibration_dataset CALIBRATION_DATASET\n",
            "                        The dataset to use to calibrate integer ranges when quantizing the model.\n",
            "                        This is needed to perform static quantization.\n",
            "  --calibration_dataset_config_name CALIBRATION_DATASET_CONFIG_NAME\n",
            "                        The calibration dataset configuration name, this is needed for some\n",
            "                        datasets.\n",
            "  --num_calibration_samples NUM_CALIBRATION_SAMPLES\n",
            "                        The number of samples in the calibration dataset to use for calibration,\n",
            "                        usually something around 100-200 is enough.\n",
            "  --calibration_split CALIBRATION_SPLIT\n",
            "                        The split of the calibration dataset to use.\n",
            "  --primary_key PRIMARY_KEY\n",
            "                        The name of the column in the dataset containing the main data to\n",
            "                        preprocess. Only for text-classification and token-classification.\n",
            "  --secondary_key SECONDARY_KEY\n",
            "                        The name of the second column in the dataset containing the main data to\n",
            "                        preprocess, not always needed. Only for text-classification and token-\n",
            "                        classification.\n",
            "  --question_key QUESTION_KEY\n",
            "                        The name of the column containing the question in the dataset. Only for\n",
            "                        question-answering.\n",
            "  --context_key CONTEXT_KEY\n",
            "                        The name of the column containing the context in the dataset. Only for\n",
            "                        question-answering.\n",
            "  --image_key IMAGE_KEY\n",
            "                        The name of the column containing the image in the dataset. Only for\n",
            "                        image-classification.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import transformers\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5TokenizerFast\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
        "from tqdm import tqdm\n",
        "from torch.optim import Adam\n",
        "\n",
        "TOKENZIER=T5TokenizerFast.from_pretrained('t5-base')\n",
        "MODEL=T5ForConditionalGeneration.from_pretrained('t5-base', return_dict=True)\n",
        "OPTIMIZER=Adam(MODEL.parameters(), lr=0.00001)\n",
        "Q_LEN=256\n",
        "T_LEN=64\n",
        "BATCH_SIZE=4\n",
        "DEVICE=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class Medical(Dataset):\n",
        "    def __init__(self,tokenizer, data, q_len, t_len):\n",
        "        self.tokenizer=tokenizer\n",
        "        self.data=data\n",
        "        self.q_len=q_len\n",
        "        self.t_len=t_len\n",
        "        self.question=self.data['question']\n",
        "        self.context=self.data['context']\n",
        "        self.answer=self.data['answer']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.question)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        question=self.question[index]\n",
        "        context=self.context[index]\n",
        "        answer=self.answer[index]\n",
        "\n",
        "        source=self.tokenizer(question, context, max_length=self.q_len, padding=\"max_length\", truncation=True, pad_to_max_length=True, add_special_tokens=True)\n",
        "        target=self.tokenizer(answer, max_length=self.t_len, padding=\"max_length\", truncation=True, pad_to_max_length=True, add_special_tokens=True)\n",
        "\n",
        "        labels=torch.tensor(target['input_ids'], dtype=torch.long)\n",
        "        labels[labels==0]=-100\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(source['input_ids'], dtype=torch.long),\n",
        "            \"attention_mask\": torch.tensor(source['attention_mask'], dtype=torch.long),\n",
        "            \"labels\": labels,\n",
        "            \"decoder_attention_mask\": torch.tensor(target['attention_mask'], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "def get_data(data):\n",
        "    articles=[]\n",
        "\n",
        "    for article in data[\"data\"]:\n",
        "        for paragraph in article[\"paragraphs\"]:\n",
        "            for qa in paragraph[\"qas\"]:\n",
        "                question=qa[\"question\"]\n",
        "                context=paragraph[\"context\"]\n",
        "                if qa[\"is_impossible\"]:\n",
        "                    answer=\"no answer\"\n",
        "                else:\n",
        "                    answer=qa[\"answers\"][0][\"text\"]\n",
        "                inputs={\"context\": context, \"question\": question, \"answer\": answer}\n",
        "                articles.append(inputs)\n",
        "    return articles\n",
        "\n",
        "\n",
        "\n",
        "with open('test_webmd_squad_v2_full.json', 'r') as f:\n",
        "    train_data = json.load(f)\n",
        "\n",
        "data=get_data(train_data)\n",
        "\n",
        "data=pd.DataFrame(data)\n",
        "\n",
        "with open('test_webmd_squad_v2_consec.json', 'r') as f:\n",
        "    test_data = json.load(f)\n",
        "\n",
        "test_data=get_data(test_data)\n",
        "\n",
        "test_data=pd.DataFrame(test_data)\n",
        "\n",
        "# DataLoaders\n",
        "\n",
        "train_sampler=RandomSampler(data.index)\n",
        "test_sampler=RandomSampler(test_data.index)\n",
        "\n",
        "medcal_dataset=Medical(TOKENZIER, data, Q_LEN, T_LEN)\n",
        "\n",
        "train_dataloader=DataLoader(medcal_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "test_dataloader=DataLoader(medcal_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "\n",
        "# Training\n",
        "\n",
        "train_loss=0\n",
        "val_loss=0\n",
        "train_batch=0\n",
        "val_batch=0\n",
        "\n",
        "for epoch in range(2):\n",
        "    print(f\"Epoch {epoch+1}/{2}\")\n",
        "    print('-'*10)\n",
        "    MODEL.train()\n",
        "\n",
        "    for batch in tqdm(train_dataloader,desc=\"Training batches\"):\n",
        "        input_ids=batch[\"input_ids\"].to(DEVICE)\n",
        "        attention_mask=batch[\"attention_mask\"].to(DEVICE)\n",
        "        labels=batch[\"labels\"].to(DEVICE)\n",
        "        decoder_attention_mask=batch[\"decoder_attention_mask\"].to(DEVICE)\n",
        "\n",
        "        OPTIMIZER.zero_grad()\n",
        "\n",
        "        outputs=MODEL(input_ids=input_ids, attention_mask=attention_mask, labels=labels, decoder_attention_mask=decoder_attention_mask)\n",
        "\n",
        "        loss=outputs.loss\n",
        "        loss.backward()\n",
        "        OPTIMIZER.step()\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "        train_batch+=1\n",
        "\n",
        "    print(f\"Train loss: {train_loss/train_batch}\")\n",
        "\n",
        "    MODEL.eval()\n",
        "\n",
        "    for batch in tqdm(test_dataloader,desc=\"Validation batches\"):\n",
        "        input_ids=batch[\"input_ids\"].to(DEVICE)\n",
        "        attention_mask=batch[\"attention_mask\"].to(DEVICE)\n",
        "        labels=batch[\"labels\"].to(DEVICE)\n",
        "        decoder_attention_mask=batch[\"decoder_attention_mask\"].to(DEVICE)\n",
        "\n",
        "        outputs=MODEL(input_ids=input_ids, attention_mask=attention_mask, labels=labels, decoder_attention_mask=decoder_attention_mask)\n",
        "\n",
        "        OPTIMIZER.zero_grad()\n",
        "        loss=outputs.loss\n",
        "        loss.backward()\n",
        "        OPTIMIZER.step()\n",
        "        val_loss+=loss.item()\n",
        "        val_batch+=1\n",
        "\n",
        "    print(f\"Validation loss: {val_loss/val_batch}\")\n",
        "\n",
        "\n",
        "# Save model\n",
        "MODEL.save_pretrained(\"qa_model\")\n",
        "TOKENZIER.save_pretrained(\"qa_model_tokenizer\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "uj1D6YaHm7gE",
        "outputId": "c2ad06b6-74f6-455f-ac66-639ad6d35ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5_fast.py:158: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d798070806b9>\u001b[0m in \u001b[0;36m<cell line: 69>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_webmd_squad_v2_full.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_webmd_squad_v2_full.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!optimum-cli export tflite --model t5-base --sequence_length 128 t5_tflite/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlR4OhdgiI0N",
        "outputId": "4e7eb66b-3bac-4a2d-95a3-92c25179aa4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-28 18:59:20.604927: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-10-28 18:59:26.910027: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optimum/exporters/tflite/__main__.py\", line 146, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optimum/exporters/tflite/__main__.py\", line 65, in main\n",
            "    tflite_config_constructor = TasksManager.get_exporter_config_constructor(model=model, exporter=\"tflite\", task=task)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optimum/exporters/tasks.py\", line 1765, in get_exporter_config_constructor\n",
            "    model_tasks = TasksManager.get_supported_tasks_for_model_type(model_type, exporter, model_name=model_name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optimum/exporters/tasks.py\", line 1058, in get_supported_tasks_for_model_type\n",
            "    raise KeyError(\n",
            "KeyError: \"t5 (tft5_for_conditional_generation) is not supported yet with the tflite backend. Only ['onnx'] are supported. If you want to support tflite please propose a PR or open up an issue.\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/optimum-cli\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optimum/commands/optimum_cli.py\", line 163, in main\n",
            "    service.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optimum/commands/export/tflite.py\", line 243, in run\n",
            "    subprocess.run(full_command, shell=True, check=True)\n",
            "  File \"/usr/lib/python3.10/subprocess.py\", line 526, in run\n",
            "    raise CalledProcessError(retcode, process.args,\n",
            "subprocess.CalledProcessError: Command 'python3 -m optimum.exporters.tflite --model t5-base --sequence_length 128 t5_tflite/' returned non-zero exit status 1.\n"
          ]
        }
      ]
    }
  ]
}